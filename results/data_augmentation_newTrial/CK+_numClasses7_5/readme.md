

### CK+ BATCH_SIZE 8 E FT_BATCH_SIZE 8

accuracy test set: 0.9895104765892029
accuracy train set: 0.9954977631568909
accuracy validation set: 0.9789842367172241
loss test set: 0.09981024265289307
loss train set: 0.016533419489860535
loss validation set: 0.15237534046173096

F1 Score: 0.9894668027198147
Precision: 0.989506327006327
Recall: 0.9895104895104895
AUC-ROC: 0.9992563227381545

### CK+ BATCH_SIZE 8 E FT_BATCH_SIZE 16

accuracy test set: 0.996503472328186
accuracy train set: 0.9979990124702454
accuracy validation set: 0.9894921183586121
loss test set: 0.011892070062458515
loss train set: 0.011707892641425133
loss validation set: 0.04530317708849907

F1 Score: 0.9965029764226552
Precision: 0.9965867465867466
Recall: 0.9965034965034965
AUC-ROC: 1.0

### CK+ BATCH_SIZE 8 E FT_BATCH_SIZE 32

accuracy test set: 0.9790209531784058
accuracy train set: 0.9974987506866455
accuracy validation set: 0.9912434220314026
loss test set: 0.06381405889987946
loss train set: 0.01248881034553051
loss validation set: 0.03707266226410866

F1 Score: 0.9791431590126369
Precision: 0.9799193055007008
Recall: 0.9790209790209791
AUC-ROC: 0.9998571902628647

### CK+ BATCH_SIZE 8 E FT_BATCH_SIZE 64

accuracy test set: 0.9895104765892029
accuracy train set: 0.9984992742538452
accuracy validation set: 0.9877408146858215
loss test set: 0.03648487105965614
loss train set: 0.016254417598247528
loss validation set: 0.05979073792695999

F1 Score: 0.9895536562203229
Precision: 0.9896810506566605
Recall: 0.9895104895104895
AUC-ROC: 0.9998995591267866

### CK+ BATCH_SIZE 16 E FT_BATCH_SIZE 8

accuracy test set: 0.139860138297081
accuracy train set: 0.13756878674030304
accuracy validation set: 0.141856387257576
loss test set: 1.949999451637268
loss train set: 1.9477001428604126
loss validation set: 1.9459940195083618

F1 Score: 0.03432150671414475
Precision: 0.019560858721697886
Recall: 0.13986013986013987
AUC-ROC: 0.5455237147123658

### CK+ BATCH_SIZE 16 E FT_BATCH_SIZE 16

accuracy test set: 1.0
accuracy train set: 0.9969984889030457
accuracy validation set: 0.985989511013031
loss test set: 0.00896520260721445
loss train set: 0.01615365967154503
loss validation set: 0.06961307674646378

F1 Score: 1.0
Precision: 1.0
Recall: 1.0
AUC-ROC: 1.0

### CK+ BATCH_SIZE 16 E FT_BATCH_SIZE 32

accuracy test set: 0.9860140085220337
accuracy train set: 0.9989994764328003
accuracy validation set: 0.9947460889816284
loss test set: 0.08518698811531067
loss train set: 0.010373860597610474
loss validation set: 0.06302742660045624

F1 Score: 0.986055072400454
Precision: 0.9862637362637362
Recall: 0.986013986013986
AUC-ROC: 0.9995404607836166

### CK+ BATCH_SIZE 16 E FT_BATCH_SIZE 64

accuracy test set: 0.996503472328186
accuracy train set: 0.9969984889030457
accuracy validation set: 0.9929947257041931
loss test set: 0.022088630124926567
loss train set: 0.020283550024032593
loss validation set: 0.02982502616941929

F1 Score: 0.9965029764226552
Precision: 0.9965867465867466
Recall: 0.9965034965034965
AUC-ROC: 0.9999857782834388

### CK+ BATCH_SIZE 32 E FT_BATCH_SIZE 8

accuracy test set: 0.9860140085220337
accuracy train set: 0.9894947409629822
accuracy validation set: 0.9842382073402405
loss test set: 0.08390649408102036
loss train set: 0.03765374794602394
loss validation set: 0.10434437543153763

F1 Score: 0.9859702992233113
Precision: 0.9860098235098236
Recall: 0.986013986013986
AUC-ROC: 0.999669641375714

### CK+ BATCH_SIZE 32 E FT_BATCH_SIZE 16

accuracy test set: 0.9930070042610168
accuracy train set: 0.9964982271194458
accuracy validation set: 0.9912434220314026
loss test set: 0.018651748076081276
loss train set: 0.02457272820174694
loss validation set: 0.038917120546102524

F1 Score: 0.993006993006993
Precision: 0.9930922735800783
Recall: 0.993006993006993
AUC-ROC: 0.9999857782834388

### CK+ BATCH_SIZE 32 E FT_BATCH_SIZE 32

accuracy test set: 0.9895104765892029
accuracy train set: 0.9984992742538452
accuracy validation set: 0.9929947257041931
loss test set: 0.06410970538854599
loss train set: 0.014666668139398098
loss validation set: 0.025852199643850327

F1 Score: 0.9894652034712277
Precision: 0.989762270250075
Recall: 0.9895104895104895
AUC-ROC: 0.9997137879542061

### CK+ BATCH_SIZE 32 E FT_BATCH_SIZE 64

accuracy test set: 0.9790209531784058
accuracy train set: 0.9969984889030457
accuracy validation set: 0.985989511013031
loss test set: 0.05341058224439621
loss train set: 0.016681743785738945
loss validation set: 0.03652023896574974

F1 Score: 0.9790010495325426
Precision: 0.9801963770495238
Recall: 0.9790209790209791
AUC-ROC: 0.9998850411244637

### CK+ BATCH_SIZE 64 E FT_BATCH_SIZE 8

accuracy test set: 0.14335663616657257
accuracy train set: 0.12656328082084656
accuracy validation set: 0.141856387257576
loss test set: 1.9460067749023438
loss train set: 1.9460409879684448
loss validation set: 1.945919394493103

F1 Score: 0.035948760719402915
Precision: 0.020551127194483838
Recall: 0.14335664335664336
AUC-ROC: 0.5

### CK+ BATCH_SIZE 64 E FT_BATCH_SIZE 16

accuracy test set: 0.9755244851112366
accuracy train set: 0.9959980249404907
accuracy validation set: 0.996497392654419
loss test set: 0.09093529731035233
loss train set: 0.02337195724248886
loss validation set: 0.037260428071022034

F1 Score: 0.9753897327355717
Precision: 0.9755810900488897
Recall: 0.9755244755244755
AUC-ROC: 0.9995567565005096

### CK+ BATCH_SIZE 64 E FT_BATCH_SIZE 32

accuracy test set: 0.9860140085220337
accuracy train set: 0.9979990124702454
accuracy validation set: 0.9877408146858215
loss test set: 0.05735078454017639
loss train set: 0.012601849623024464
loss validation set: 0.06065618619322777

F1 Score: 0.9860545259864053
Precision: 0.9862637362637362
Recall: 0.986013986013986
AUC-ROC: 0.9998571902628647

### CK+ BATCH_SIZE 64 E FT_BATCH_SIZE 64

accuracy test set: 0.9860140085220337
accuracy train set: 0.9984992742538452
accuracy validation set: 0.9929947257041931
loss test set: 0.07135152071714401
loss train set: 0.010861841030418873
loss validation set: 0.053048450499773026

F1 Score: 0.9860452931283162
Precision: 0.9866395259751902
Recall: 0.986013986013986
AUC-ROC: 0.9993158761762544

## Analisi dei risultati dei modelli CK+

* **Overfitting:** Modelli con grandi batch size e FT_BATCH_SIZE tendono ad avere un rischio di overfitting più basso.
* **Accuratezza:** Modelli con batch size e FT_BATCH_SIZE maggiori spesso raggiungono accuratezze più elevate.
* **Loss:** La perdita generalmente diminuisce con l'aumento di batch size e FT_BATCH_SIZE.

**Migliori modelli:**

* **BATCH_SIZE 16 E FT_BATCH_SIZE 16:** Questo modello presenta un ottimo equilibrio tra accuratezza, perdita e overfitting. Ha un'accuratezza molto elevata (1.0) e una perdita bassa, senza segni evidenti di overfitting.
* **BATCH_SIZE 8 E FT_BATCH_SIZE 16:** Questo modello ha un'accuratezza leggermente inferiore rispetto al precedente, ma presenta comunque ottime prestazioni. La perdita è bassa e il rischio di overfitting sembra contenuto.

**Considerazioni:**

* **Computational Cost:** Modelli con batch size e FT_BATCH_SIZE maggiori richiedono più risorse computazionali.
* **Specific Use Case:** La scelta del modello migliore dipende dalle specifiche esigenze. Se priorizzi l'accuratezza, il BATCH_SIZE 16 E FT_BATCH_SIZE 16 potrebbe essere la scelta migliore. Se invece hai limitazioni computazionali, potresti considerare il BATCH_SIZE 8 E FT_BATCH_SIZE 16.

**Conclusioni**

In generale, i risultati mostrano che l'ottimizzazione dei parametri BATCH_SIZE e FT_BATCH_SIZE ha un impatto significativo sulle prestazioni del modello. Scegliendo la configurazione giusta, puoi ottenere un modello accurato, affidabile ed efficiente.
